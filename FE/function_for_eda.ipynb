{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "229fb04c",
   "metadata": {},
   "source": [
    "# 1. Function to visualize "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dc5714",
   "metadata": {},
   "source": [
    "1. Function to get dtype of column\n",
    "- `get_column_names_by_type(df)`: phân loại các cột theo từng dtype\n",
    "\n",
    "2. Funtion to get some basic information:\n",
    "- `print_basic_information()`: in ra một số thông tin cơ bản của dataframe như: shape, dupplicated,..\n",
    "\n",
    "3. Function for count nan values\n",
    "- `count_missing_values(df)`: đếm số lượng giá trị nan và tính phần trăm nan trong từng cột\n",
    "\n",
    "4. Function for plot nan percent values\n",
    "- `plot_missing_values_percent()`: visualize bằng biểu đồ đường về phần trăm giá trị nan trong cột của dataframe\n",
    "\n",
    "5. Function print unique value\n",
    "- `print_unique_categories()`: in số lượng bản ghi cho từng category ở biến categorical\n",
    "\n",
    "6. Function plot categorical variables\n",
    "- `plot_categorical_variables()`: visualize các biến categorical bằng 2 biểu đồ.\n",
    "  - 'count_display': thể hiện số lượng bản ghi trong từng category trong 1 cột. \n",
    "  - 'plot_defaulter': Phần trăm bản ghi là nợ xấu trong từng category trong 1 cột\n",
    "\n",
    "7. Function plot continuous variables:\n",
    "- `plot_numerical_variables()`: visualize các biến numerical bằng 3 biểu đồ. \n",
    "  - 'hist_plot': biểu đồ histogram thể hiện phân phối của biến\n",
    "  - 'dist_plot': thể hiện phân phối của biến theo từng nhãn của biến TARGET\n",
    "  - 'box_plot': biểu đồ thể hiện phân phối của biến dựa trên các giá trị                quantiles -> nhìn các giá trị ngoại biên, giá trị  bất                    thường\n",
    "  \n",
    "8. Function plot correlation\n",
    "- `correlation_matrix()`: biểu đồ heatmap thể hiện hệ số tương quan của những feature với nhau mà những features này là features có hệ số tương quan cao với biến 'TARGET'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "693a4f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import phik\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler, LabelEncoder, OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "\n",
    "#import import_ipynb\n",
    "#from function_for_eda import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "679fe5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_missing_values(df):\n",
    "    \n",
    "    '''\n",
    "    Function to count missing values in a DataFrame\n",
    "\n",
    "    Inputs:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "\n",
    "    Outputs:\n",
    "    - df_nan: A dataframe has two columns: the numbers of missing value and the percentage of missing values which indexs\n",
    "             are the column name of original dataframe\n",
    "    '''\n",
    "    \n",
    "    total_nan = df.isnull().sum()\n",
    "    percent_nan = 100 * df.isnull().sum() / len(df) \n",
    "    \n",
    "    df_nan = pd.concat([total_nan, percent_nan], axis=1)  \n",
    "    df_nan = df_nan.rename(columns = {0: 'total_nan', 1: 'percent_nan'})\n",
    "    \n",
    "    df_nan = df_nan[df_nan.iloc[:,1] != 0].sort_values(by = 'percent_nan', ascending=False)\n",
    "    print(f\"Your data frame has {df.shape[1]} columns.\\nThere are {df_nan.shape[0]} columns that have missing values.\" )\n",
    "    return df_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96d155fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_missing_values_percent(df, title_name, tight_layout = True, figsize = (20,8), grid = False, rotation = 90):\n",
    "    \n",
    "    '''\n",
    "    Function to plot Line Plots of missing value percentages for each column in a dataframe\n",
    "    \n",
    "    Inputs:   \n",
    "    - df: a DataFrame \n",
    "    \n",
    "    - title_name: Name of table to be displayed in title of plot\n",
    "    \n",
    "    - tight_layout: bool, default = True. Whether to keep tight layout or not\n",
    "    \n",
    "    - figsize: tuple, default = (20,8) Figure size of plot \n",
    "    \n",
    "    - grid: bool, default = False. Whether to draw gridlines to plot or not\n",
    "    \n",
    "    - rotation: int, default = 0. Degree of rotation for x-tick labels\n",
    "    \n",
    "    '''\n",
    "    df_nan = count_missing_values(df).reset_index()\n",
    "    if df_nan['percent_nan'].sum() != 0:\n",
    "        \n",
    "        #plotting the Point-Plot for NaN percentages (only for columns with Non-Zero percentage of NaN values)\n",
    "        plt.figure(figsize = figsize, tight_layout = tight_layout)\n",
    "        sns.pointplot(x= 'index', y = 'percent_nan', data = df_nan[['index','percent_nan']], color = 'maroon')\n",
    "        plt.xticks(rotation = rotation)\n",
    "        plt.xlabel('Column Name')\n",
    "        plt.ylabel('Percentage of NaN values')\n",
    "        plt.title(f'Percentage of NaN values in {title_name}')\n",
    "        if grid:\n",
    "            plt.grid()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"The dataframe {title_name} does not contain any NaN values.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e65d9450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_names_by_type(df):\n",
    "    \n",
    "    '''\n",
    "    Function to get column names grouped by data type in a DataFrame.\n",
    "    \n",
    "    Inputs:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "    \n",
    "    Outputs:\n",
    "    - dict: Dictionary where keys are data types, and values are lists of column names.\n",
    "    \n",
    "    '''\n",
    "    # Get data types of each column\n",
    "    column_data_types = df.dtypes\n",
    "\n",
    "    # Initialize an empty dictionary to store column names for each data type\n",
    "    column_names_by_type = {}\n",
    "\n",
    "    # Iterate through columns and populate the dictionary\n",
    "    for column_name, data_type in column_data_types.items():\n",
    "        # Convert data type to string for better readability\n",
    "        data_type_str = str(data_type)\n",
    "        \n",
    "        # Check if the data type is already a key in the dictionary\n",
    "        if data_type_str in column_names_by_type:\n",
    "            # Append the column name to the existing list for that data type\n",
    "            column_names_by_type[data_type_str].append(column_name)\n",
    "        else:\n",
    "            # Create a new list with the column name for the data type\n",
    "            column_names_by_type[data_type_str] = [column_name]\n",
    "\n",
    "    return column_names_by_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64ecd544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_basic_information(df, title_name, key = [], print_dtype = False):\n",
    "    \n",
    "    '''\n",
    "    Function to print some basic information of dataframe: shape, numbers of duplicate values\n",
    "                                                           number of unique value in each ID column\n",
    "    Inputs:\n",
    "    - df: a DataFrame \n",
    "    \n",
    "    - title_name: a string is name of table to be displayed\n",
    "    \n",
    "    - key: a list include ID columns(ex: SK_ID_CURR. SK_ID_BUREAU)\n",
    "    \n",
    "    - print_dtype: bool, default = False. Whether to print dtype of each column or not\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    print(f'The shape of {title_name} is: {df.shape}')\n",
    "    print('-'*100)\n",
    "    print(f'Number of duplicate values in {title_name}: {df.shape[0] - df.duplicated().shape[0]}')\n",
    "    print('-'*100)\n",
    "    if len(key) > 0:\n",
    "        for a in key:\n",
    "            print(f'Number of unique {a} in {title_name} are: {len(df[a].unique())}')\n",
    "    else:\n",
    "        pass\n",
    "    if print_dtype:\n",
    "        print('-'*100)\n",
    "        dtype_dict = get_column_names_by_type(df)\n",
    "        for data_type, columns in dtype_dict.items():\n",
    "            # Print the data type\n",
    "            print(data_type + ':')\n",
    "\n",
    "            # Print each column in the list as a separate row\n",
    "            for column in columns:\n",
    "                print('- ' + column)\n",
    "\n",
    "            # Add a newline for better readability between data types\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca999e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_unique_categories(df, column_name, show_counts = False):\n",
    "    \n",
    "    '''\n",
    "    Function to print the basic stats such as unique categories and their counts for categorical variables\n",
    "    \n",
    "    Inputs:\n",
    "    - df: DataFrame. The DataFrame from which to print statistics\n",
    "    \n",
    "    - column_name: str. Column's name whose stats are to be printed \n",
    "    \n",
    "    - show_counts: bool, default = False. Whether to show counts of each category or not\n",
    "\n",
    "    '''\n",
    "    \n",
    "    print('-'*100)\n",
    "    print(f\"The unique categories of '{column_name}' are:\\n{df[column_name].unique()}\")\n",
    "    print('-'*100)\n",
    "    \n",
    "    if show_counts:\n",
    "        print(f\"Counts of each category are:\\n{df[column_name].value_counts()}\")\n",
    "        print('-'*100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eea07ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_categorical_variables(df, column_name, figsize = (18, 6), count_display = True, plot_defaulter = True):\n",
    "    \n",
    "    '''\n",
    "    Function to plot Categorical Variables Bar Plots\n",
    "    \n",
    "    Inputs:\n",
    "    - df: DataFrame. The DataFrame from which to plot\n",
    "    \n",
    "    - column_name: str. Column's name whose distribution is to be plotted\n",
    "    \n",
    "    - figsize: tuple, default = (18,6). Size of the figure to be plotted\n",
    "    \n",
    "    - count_display: bool, default = True. Whether to display the bar plot show the number of contracts per each category in a column\n",
    "    \n",
    "    - plot_defaulter: bool. default = True. Whether to plot the Bar Plots for Defaulters or not\n",
    "    \n",
    "    '''\n",
    "    print(f\"Total Number of unique categories of {column_name} = {len(df[column_name].unique())}\")\n",
    "    plt.figure(figsize = figsize, tight_layout = False)\n",
    "    sns.set(style = 'whitegrid', font_scale = 1.2)\n",
    "    \n",
    "    #plotting overall distribution of category\n",
    "    data_to_plot = df[column_name].value_counts()\n",
    "    df_to_plot = pd.DataFrame({column_name: data_to_plot.index, 'Number of contracts': data_to_plot.values})\n",
    "    \n",
    "    # Calculate the percentage of target = 1 per category \n",
    "    default_percent = df[[column_name, 'TARGET']].groupby([column_name], as_index = False)['TARGET'].mean()\n",
    "    default_percent.sort_values(by = 'TARGET', ascending = False, inplace = True)\n",
    "    \n",
    "    if count_display:\n",
    "        plt.subplot(1,2,1)\n",
    "        s1 = sns.barplot(x = 'Number of contracts', y = column_name, data = df_to_plot)\n",
    "        #s1.set_yticklabels(s1.get_yticklabels(),rotation = 90)\n",
    "        plt.title(f'Distribution of {column_name}', pad = 20)\n",
    "\n",
    "    if plot_defaulter:\n",
    "        plt.subplot(1,2,2)\n",
    "        s2 = sns.barplot(x = 'TARGET', y = column_name, data = default_percent)\n",
    "        #s2.set_yticklabels(s2.get_yticklabels(),rotation=90)\n",
    "        plt.xlabel('Proportion', fontsize=16)\n",
    "        plt.title(f'Proportion of Defaulters for each category of {column_name}', pad = 20)\n",
    "\n",
    "        \n",
    "    plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "    plt.subplots_adjust(wspace = 0.4)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a034a980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_numerical_variables(df, column_name, figsize = (20,8), hist_plot = True, box_plot = True, dist_plot = True, number_of_subplots = 3):\n",
    "    \n",
    "    '''\n",
    "    Function to plot continuous variables distribution\n",
    "    \n",
    "    Inputs:\n",
    "    - df: DataFrame. The DataFrame from which to plot.\n",
    "    \n",
    "    - column_name: str. Column's name whose distribution is to be plotted.\n",
    "    \n",
    "    - figsize: tuple, default = (20,8). Size of the figure to be plotted.\n",
    "    \n",
    "    - hist_plot: bool, default = True. Whether to plot histogram chart for column\n",
    "    \n",
    "    - box_plot: bool, default = True. Whether to plot box plot to analyze the whole range of values in continuous variable or not\n",
    "        \n",
    "    - dist_plot: bool, default = True. Whether to plot the PDFs of the variable along to each target label.\n",
    "    \n",
    "    - number_of_subplots: int. Total number of chart want to be plotted.\n",
    "    \n",
    "    '''\n",
    "    plt.figure(figsize = figsize)\n",
    "    sns.set_style('whitegrid')\n",
    "    sns.color_palette(\"RdBu\", 10)\n",
    "    i = 1\n",
    "\n",
    "    if hist_plot:\n",
    "        plt.subplot(1, number_of_subplots, i)\n",
    "        plt.subplots_adjust(wspace=0.25)   \n",
    "        plt.title(\"Distribution of %s\" %column_name)\n",
    "        sns.distplot(df[column_name].dropna(),color='red', kde=True,bins=100)\n",
    "        i+= 1\n",
    "        \n",
    "    if dist_plot:\n",
    "        plt.subplot(1, number_of_subplots, i)\n",
    "        plt.subplots_adjust(wspace=0.25) \n",
    "        \n",
    "        sns.distplot(df[column_name][df['TARGET'] == 0].dropna(),\\\n",
    "                     label='Non-Defaulters', hist = False, color = 'firebrick')\n",
    "        sns.distplot(df[column_name][df['TARGET'] == 1].dropna(),\\\n",
    "                     label='Defaulters', hist = False, color = 'dodgerblue')\n",
    "\n",
    "        plt.xlabel(column_name)\n",
    "        plt.ylabel('Probability Density')        \n",
    "        plt.title(\"Dist-Plot of {}\".format(column_name))\n",
    "        plt.legend(loc=\"best\", labels=['Non-Defaulted(TARGET=0)', 'Defaulted (TARGET = 1)'], fontsize = 'medium')  \n",
    "        plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "        i+= 1   \n",
    "        \n",
    "    if box_plot:  \n",
    "        plt.subplot(1, number_of_subplots, i)\n",
    "        plt.subplots_adjust(wspace=0.25) \n",
    "        \n",
    "        sns.boxplot(x='TARGET', y=column_name, data=df)\n",
    "        plt.title(\"Box-Plot of {}\".format(column_name))\n",
    "\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11ab7e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_matrix(df, number_of_feature, numerical = True, categorical = False):\n",
    "    \n",
    "    '''\n",
    "    Function to plot the heatmap show the correlation of other features to 'TARGET'\n",
    "    Inputs:\n",
    "    - df: DataFrame. The DataFrame from which to plot.\n",
    "    - Number_of_feature: int. The top number of feature which have highest correlation with 'TARGET'.\n",
    "    - numerical : bool. Default = True: correlation heatmap giữa các biến numerical với nhau\n",
    "    - categorical: bool. Default = False: correlation phik giữa các biến categorical với nhau và với biến TARGET\n",
    "    \n",
    "    ''' \n",
    "    \n",
    "    if numerical:\n",
    "        numeric_columns = df.select_dtypes(include=['number']).columns.tolist()       \n",
    "        df = df[numeric_columns]\n",
    "        correlations = df.corr()['TARGET']\n",
    "\n",
    "        corr_top = np.abs(correlations).sort_values(ascending=False)[:number_of_feature].index.tolist()    \n",
    "        cols_tbl = df[corr_top].corr()\n",
    "\n",
    "        plt.figure(figsize = (13,10))\n",
    "        sns.heatmap(cols_tbl, cmap = plt.cm.RdYlBu_r, annot = True)\n",
    "       \n",
    "    if categorical:\n",
    "        categorical_columns = df.dtypes[df.dtypes == 'object'].index.tolist()\n",
    "        data_for_phik = df[categorical_columns+ ['TARGET']]\n",
    "        \n",
    "        phik_matrix = data_for_phik.phik_matrix().sort_values(by = 'TARGET', ascending = False) \n",
    "        corr_top_cat = phik_matrix[:number_of_feature].index.tolist()\n",
    "        \n",
    "        corr_matrix_cat = df[corr_top_cat].phik_matrix()\n",
    "        \n",
    "        plt.figure(figsize = (10,10))      \n",
    "        sns.heatmap(corr_matrix_cat, cmap = 'Blues')\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72668c42",
   "metadata": {},
   "source": [
    "# 2. Function to pre-processing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b73779",
   "metadata": {},
   "source": [
    "1. `remove_missing_col()`: xóa đi những cột có phần trăm missing value cao hơn ngưỡng threshold\n",
    "2. `fillna()`: Fill các giá trị nan values. Trong đó các biến numeric được fill bằng giá trị trung bình(mean) còn các biến categorical sẽ được fill bằng giá trị xuất hiện nhiều nhất(mode)\n",
    "3. `create_day_to_year()`: chuyển những cột chưa số lượng theo đơn vị ngày thành đơn vị năm\n",
    "4. `check_imbalance()`: Kiểm tra xem những cột chưa 2 giá trị unique có bị mất cân bằng không\n",
    "5. `drop_column_unique_value()`: Nếu những cột đấy bị mất cân bằng(hàm số 4) thì sẽ bị drop\n",
    "6. `get_thresh()`, `change_value()`, `replace_outlier()`: Tìm ngưỡng để xác định các giá trị outliers. Ở đây các ngưỡng sử dụng phương pháp 3 sigma để điều chỉnh lại các giá trị nằm ngoài miền  [μ−3σ,μ+3σ] về trong miền giá trị đó. Đối với giá trị lớn hơn  μ+3σ sẽ được gán bằng  μ+3σ và tương tự với giá trị nhỏ hơn  μ−3σ\n",
    "7. `encode()`: Encoding các biến categorical. Với các cột chỉ có 2 unique values thì encode bằng LabelEncoder(), và những cột nhiều hơn 2 unique values thì encode bằng OneHotEncoder()\n",
    "\n",
    "Tuy nhiên đây chỉ funtion chung cho tất cả các bảng. Tùy từng bảng mà sẽ có những điều chỉnh phù hợp và mang lại kết quả auc tốt nhất"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e1216a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing value\n",
    "def remove_missing_col(df, threshold = 0.6):\n",
    "    '''\n",
    "    Function to drop columns from the DataFrame where the percentage of missing values is greater than the threshold.\n",
    "\n",
    "    Inputs:\n",
    "    - df: a DataFrame\n",
    "    - threshold: float, default = 0.6. The threshold for the percentage of missing values. Columns with missing values \n",
    "                percentage greater than this threshold will be dropped.\n",
    "\n",
    "    Outputs:\n",
    "    - df: a DataFrame. DataFrame with columns dropped based on the specified threshold.\n",
    "    \n",
    "    '''\n",
    "    # Calculate the percentage of missing values for each column\n",
    "    missing_percentage = df.isnull().mean()\n",
    "\n",
    "    # Identify columns where the missing percentage is greater than the threshold\n",
    "    columns_to_drop = missing_percentage[missing_percentage > threshold].index\n",
    "\n",
    "    # Drop the identified columns from the DataFrame\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "    return df\n",
    "\n",
    "def fill_nan(df):\n",
    "    '''\n",
    "    Function to fill values for missing data where numerical data fill by mean method, and categorical \n",
    "    data fiil by mode method.\n",
    "    \n",
    "    Inputs:\n",
    "    - df: a DataFrame\n",
    "    \n",
    "    Outputs:\n",
    "    - df: a DataFrame do not include missing values.\n",
    "    \n",
    "    '''\n",
    "    numeric_columns = df.select_dtypes(include=['number']).columns.tolist()\n",
    "    df[numeric_columns] = df[numeric_columns].fillna(df[numeric_columns].mean())\n",
    "    \n",
    "    categorical_columns = df.dtypes[df.dtypes == 'object'].index.tolist()\n",
    "    df[categorical_columns] = df[categorical_columns].fillna(df[categorical_columns].mode())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4f14a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_day_to_year(df,ls_cols,newcol):\n",
    "    \n",
    "    '''\n",
    "    Function to change the columns having days value to year values\n",
    "    \n",
    "    Inputs:\n",
    "    - df: a DataFrame\n",
    "    - ls_cols: list. Including the name of columns want to be changed\n",
    "    - new_col: list. Including the new names for columns changed\n",
    "    \n",
    "    Outputs:\n",
    "    - df: a DataFrame which replacing day columns by year columns.\n",
    "    '''\n",
    "    for i, j in zip(ls_cols, newcol):\n",
    "        df[j] = round(np.abs(df[i]/365))\n",
    "        df.drop(columns = i,inplace=True);\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0dcdd1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_imbalance(series):\n",
    "    \n",
    "    '''\n",
    "    Function to check whether the series is imbalanced or not\n",
    "    Inputs:\n",
    "    - series: a series\n",
    "    Outputs:\n",
    "    - a bool: True of False that the series is imblanced greater than 98%\n",
    "    \n",
    "    '''\n",
    "    value_counts = series.value_counts(normalize=True)\n",
    "    return value_counts.max() > 0.98\n",
    "\n",
    "def drop_column_unique_value(df):\n",
    "    ''' \n",
    "    Function to drop columns with 2 unique values and imbalance > 98%\n",
    "    Inputs:\n",
    "    - df: a DataFrame\n",
    "    Outputs:\n",
    "    - df: a DataFrame removed imbalanced columns\n",
    "    '''\n",
    "    filtered_columns = [col for col in df.columns if df[col].nunique() > 2 or not check_imbalance(df[col])]\n",
    "\n",
    "    # Create a new DataFrame with selected columns\n",
    "    df_filtered = df[filtered_columns]\n",
    "    return df_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ceeaa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Xử lý Outliers\n",
    "def get_thresh(col, df):\n",
    "    '''\n",
    "    Function to get the threshold for oulier values\n",
    "    Inputs:\n",
    "    - col: the column name to check outlier\n",
    "    - df: a dataframe\n",
    "    Outputs:\n",
    "    - low threshold and upper threshold\n",
    "\n",
    "    '''\n",
    "    xs = df[col]\n",
    "    mu = xs.mean()\n",
    "    sigma = xs.std()\n",
    "    low =  mu - 3*sigma\n",
    "    high = mu + 3*sigma\n",
    "    return low, high\n",
    "    \n",
    "def change_value(x, low, high):\n",
    "    if x < low: \n",
    "        return low\n",
    "    elif x > high: \n",
    "        return high\n",
    "    else: \n",
    "        return x\n",
    "\n",
    "def replace_outlier(df):\n",
    "    '''\n",
    "    Function to replace outlier. Replacing Ouliers are lower than low threshold by low threshold and vice verse.\n",
    "    Inputs:\n",
    "    - df: a DataFrame\n",
    "    Outputs:\n",
    "    - df: a DataFrame which was handled outliers.\n",
    "    '''\n",
    "    num_columns = df.select_dtypes(include=['int64', 'float64'])\n",
    "    for col in num_columns.columns:\n",
    "        if col == 'TARGET':\n",
    "            pass\n",
    "        else:\n",
    "            low, high = get_thresh(col, df)\n",
    "            df[col] = df[col].apply(lambda x: change_value(x, low, high))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10c7b8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def encode(df):\n",
    "    '''\n",
    "    Function to encode the categorical variables in which the columns have only 2 unique values encoding by LabelEncoder\n",
    "    and remaining column by OneHOtEncoder.\n",
    "    Inputs:\n",
    "    - df: a DataFrame\n",
    "    Outputs:\n",
    "    - df: a DataFrame which was encoded.\n",
    "    '''\n",
    "    label = LabelEncoder()\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        nunique_cols = df[col].nunique()\n",
    "        if nunique_cols == 2:\n",
    "            df[col] = label.fit_transform(df[col])\n",
    " \n",
    "    df = pd.get_dummies(df)\n",
    "    return df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
